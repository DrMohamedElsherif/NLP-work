{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rVnCcGVh3gV"
   },
   "source": [
    "<span style=\"color:red\">Abgegeben von (Name, Vorname):</span>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Elsherif, Mohamed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-_XfKUZh3gX"
   },
   "source": [
    "<p style=\"line-height:1.4\">\n",
    "<font size=\"6\"><strong>3. Sitzung: Rechtschreibkorrektur & morphologische Ähnlichkeitsmaße</strong></font>\n",
    "</p>\n",
    "\n",
    "In diesem Notebook werden wir uns wieder mit Wortformen beschäftigen. Allerdings werden wir die Wortformen diesmal nicht vereinheitlichen, sondern deren Unterschiede bzw. Ähnlichkeiten messen.\n",
    "\n",
    "Ähnlichkeitsmaße bei Wortformen spielen eine wichtige Rolle bei vielen Verfahren der NLP, insbesondere bei der **Rechtschreibkorrektur**, die wir in diesem Notebook ebenfalls behandeln werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0F9P8ujh3gX"
   },
   "source": [
    "# Rechtschreibkorrektur: Genereller Aufbau\n",
    "\n",
    "Verfahren zur Rechtschreibkorrektur haben mindestens die folgenden Komponenten:\n",
    "\n",
    "- Eingabe: Wortform (ggf. mit weiterem Kontext)\n",
    "- Wissen: Korrekte Wortformen\n",
    "- Ähnlichkeitsmaß\n",
    "- Ausgabe: Korrekturvorschläge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx7dhk_mh3gY"
   },
   "source": [
    "<div>\n",
    "<img src=\"attachment:spellchecking.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vG8GH7wh3gY"
   },
   "source": [
    "Im Prinzip funktionieren so auch aktuelle Korrekturhilfen wie [Aspell](http://aspell.net/man-html/Aspell-Suggestion-Strategy.html#Aspell-Suggestion-Strategy) oder [Hunspell](https://hunspell.github.io/). Wir werden im Folgenden sehen, wie das für das Englische umgesetzt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn0J7zWDh3gY"
   },
   "source": [
    "# Ähnlichkeitsmaße bei Wortformen\n",
    "\n",
    "Grundsätzlich gilt:\n",
    "\n",
    "    Ähnlichkeitsmaß = Ähnlichkeitseigenschaft(en) + Gewichtung(en)\n",
    "    \n",
    "Eine **Ähnlichkeitseigenschaft** kann zum Beispiel sein:\n",
    "- Identität (offensichtlich zu trivial)\n",
    "- Länge des längsten gemeinsamen Teilstrings (Longest Common Substring)\n",
    "- Mächtigkeit/Kardinalität der Schnittmenge der gemeinsamen Teilstrings (Jaccard Distance)\n",
    "- Länge der Sequenz von Änderungsoperationen (Edit Distance)\n",
    "\n",
    "Eine **Gewichtung** kann sich zum Beispiel ergeben aus:\n",
    "- Länge der Wortformen\n",
    "- Wahrscheinlichkeit der Wortformen\n",
    "- Nähe der Buchstaben auf der Tastatur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGiVfOZLh3gY"
   },
   "source": [
    "## Longest Common Substring (LCS)\n",
    "\n",
    "Der längster gemeinsame Teilstring (Longest Common Substring, LCS) lässt sich folgendermaßen definieren:\n",
    "\n",
    "$$LCS(w_1,w_2) = \\underset{w \\trianglelefteq w1, w \\trianglelefteq w2}{\\operatorname{arg\\,max}} |w|$$\n",
    "\n",
    "Strenggenommen können zwei Strings mehrere LCS besitzen, aber das kümmert uns hier nicht, denn wir sind nur an der Länge eines LCS interessiert.\n",
    "\n",
    "Zur Berechnung des LCS benötigen wir zunächst eine Funktion, die die Teilstrings eines Strings ausgibt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VP7tD1Jch3gY",
    "outputId": "c0803b2b-510a-4e12-aa75-6eeb507cf8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'xec', 'xecuti', 'execution', 'xecu', 'io', 'ecu', 'c', 'execut', 'utio', 'xecution', 'executi', 'executio', 'cu', 't', 'uti', 'ution', 'ti', 'tion', 'tio', 'execu', 'i', 'ex', 'ut', 'x', 'exe', 'ion', 'ec', 'xecut', 'cuti', 'on', 'xe', 'n', 'ecutio', 'ecut', 'ecuti', 'xecutio', 'exec', 'u', 'o', 'cution', 'ecution', 'cut', 'e', 'cutio'}\n"
     ]
    }
   ],
   "source": [
    "def set_of_substrings(string, minlen=1, maxlen=999):\n",
    "    return set([string[i: j]\n",
    "                for i in range(len(string))\n",
    "                for j in range(i + 1, len(string) + 1)\n",
    "                if j-i >= minlen and j-i <= maxlen\n",
    "                ])\n",
    "\n",
    "\n",
    "print(set_of_substrings(\"execution\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBhlhLeIh3gZ"
   },
   "source": [
    "Diese Funktion hat offensichtlich eine quadratische Laufzeit (und Speicherverbrauch) in der Länge der Eingabe – nicht schön, aber für unsere Zwecke reicht das."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOpoDVVjh3gZ"
   },
   "source": [
    "Damit können wir die Menge der gemeinsamen Teilstrings und schließlich den längsten gemeinsamen Teilstring berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SEujkqmh3gZ",
    "outputId": "e269ab21-112a-4b11-cfb6-7b3e2d660951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t', 'ti', 'tion', 'o', 'io', 'tio', 'n', 'on', 'i', 'e', 'ion'}\n"
     ]
    }
   ],
   "source": [
    "def common_set_of_substrings(string1, string2, minlen=1, maxlen=999):\n",
    "    return set_of_substrings(string1, minlen, maxlen) & set_of_substrings(string2, minlen, maxlen)\n",
    "\n",
    "\n",
    "print(common_set_of_substrings(\"execution\", \"intention\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b852vNJh3ga",
    "outputId": "5d2a8661-a5e1-48c7-9333-55814535ee6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tion\n"
     ]
    }
   ],
   "source": [
    "def longest_common_substring(string1, string2):\n",
    "    css = common_set_of_substrings(string1, string2)\n",
    "    if len(css) > 1:\n",
    "        return max(css, key=len)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "print(longest_common_substring(\"execution\", \"intention\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkvxIJffh3ga"
   },
   "source": [
    "<span style=\"color:red\">Frage am Rande:</span> Wie ließe sich der längste gemeinsame Teilstring in linearer Zeit (in der Länge der Eingabe) ermitteln? Wäre das auf jeden Fall besser?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZYA5IOph3ga"
   },
   "source": [
    "Was die Gewichtung betrifft, bietet sich die Länge des kleineren Strings an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMEneE8Mh3ga",
    "outputId": "81798a7f-ac1f-44e5-f763-48587a825e02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lcs_sim(string1, string2):\n",
    "    return len(longest_common_substring(string1, string2)) / min(len(string1), len(string2))\n",
    "\n",
    "\n",
    "lcs_sim(\"execution\", \"intention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl6yvqTLh3gb"
   },
   "source": [
    "Das Problem ist hier natürlich, dass die Unterschiede zwischen zwei Wörtern so verteilt sein können, dass dieses Ähnlichkeitsmaß bei diesen Wörtern trotz der offensichtlichen Ähnlichkeit verhältnismäßig gering ausfällt.\n",
    "\n",
    "Beispiele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lVtK2Gth3gb",
    "outputId": "fc7f6112-af06-4120-d688-7c0aff40d6b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution, execUtion: 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "w1 = \"execution\"\n",
    "w2 = \"execUtion\"\n",
    "print(\"{}, {}: {}\".format(w1,w2,lcs_sim(w1,w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jELvlCeNh3gb"
   },
   "source": [
    "LCS ist also ein simples aber auch etwas \"naives\" Maß für die Ähnlichkeit zweier Wörter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygcn3mNlh3gb"
   },
   "source": [
    "## Teilstring-Überlappung (aka Jaccard-Distanz)\n",
    "\n",
    "Ein anderes Ähnlichkeitsmaß, bekannt als **Jaccard-Distanz (JD)**, betrachtet die *Überschneidung* der Mengen der Teilstrings und gewichtet diese anhand der *Vereinigung* der beiden Mengen:\n",
    "\n",
    "$$jd(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "Hier wären $A$ und $B$ die Mengen der Substrings zweier Wortformen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUopXJylh3gb"
   },
   "source": [
    "Mit den oben eingeführten Funktionen lässt sich dies direkt umsetzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5ezY_RLh3gc",
    "outputId": "a03a610c-45b4-4fda-ad71-8dd4fbf3fed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution, intention: 0.1506849315068493\n",
      "execution, execUtion: 0.2753623188405797\n"
     ]
    }
   ],
   "source": [
    "def jd_sim(string1, string2):\n",
    "    return len(common_set_of_substrings(string1, string2)) / len(set_of_substrings(string1) | set_of_substrings(string2))\n",
    "\n",
    "\n",
    "w1 = \"execution\"\n",
    "w2 = \"intention\"\n",
    "print(\"{}, {}: {}\".format(w1, w2, jd_sim(w1,w2)))\n",
    "\n",
    "w1 = \"execution\"\n",
    "w2 = \"execUtion\"\n",
    "print(\"{}, {}: {}\".format(w1, w2, jd_sim(w1,w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pAMF7FRh3gc"
   },
   "source": [
    "Die JD-Ähnlichkeit zwischen *execution* und *execUtion* ist nun erfreulicherweise größer als die zwischen *execution* und *intention* – im Unterschied zur LCS-Ähnlichkeit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDiD5E9Oh3gc"
   },
   "source": [
    "## <span style=\"color:red\">Aufgaben I</span>\n",
    "\n",
    "<span style=\"color:red\">A1:</span> Implementieren Sie eine toleranteres Ähnlichkeitsmaß auf Grundlage von LCS als `almost_lcs_sim()`, indem Sie im längsten gemeinsamen Teilstring kleinere Abweichungen zulassen, zum Beispiel hinsichtlich:\n",
    "\n",
    "- Groß-Kleinschreibung\n",
    "- benachbarte Buchstaben auf der Tastatur\n",
    "- Verdopplungen\n",
    "- Auslassungen\n",
    "- Affigierung\n",
    "- ...\n",
    "\n",
    "Diese müssen natürlich anders gewichtet werden als die echten Teilstrings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "j86ZdPDDncOf"
   },
   "outputs": [],
   "source": [
    "def almost_lcs_sim(string1, string2):\n",
    "    out = \"Ätsch!\"\n",
    "    # Dictionary für benachbarte Tasten auf einer typischen QWERTZ-Tastatur mit ChatGPT generiert\n",
    "    # Um kleinere Tippfehler zu identifizieren, bei denen möglicherweise Tasten in der Nähe mistakenly gedrückt wurden\n",
    "    Tasta_Nachbarn = {\n",
    "        'q': 'wa', 'w': 'qes', 'e': 'wsd', 'r': 'edf', 't': 'rfgy', 'z': 'tyu', 'u': 'yzih', 'i': 'ujko', 'o': 'iklp', 'p': 'ol',\n",
    "        'ü': 'io', 'a': 'qwsz', 's': 'awedxz', 'd': 'serfcx', 'f': 'drtgv', 'g': 'ftyhbv', 'h': 'gyujbn', 'j': 'huikmn', 'k': 'jiolm', 'l': 'kop',\n",
    "        'ö': 'lp', 'ä': 'öp', 'y': 'zu', 'x': 'zsdc', 'c': 'xdfv', 'v': 'cfgb', 'b': 'vghn', 'n': 'bhjm', 'm': 'njk',\n",
    "        'ß': 'm',\n",
    "        '1': '2q', '2': '13w', '3': '24e', '4': '35r', '5': '46t', '6': '57z', '7': '68u', '8': '79i', '9': '8o', '0': '9p',\n",
    "        '-': '=p', '=': '-+',\n",
    "        '!': '1q', '@': '2w', '#': '3e', '$': '4r', '%': '5t', '&': '6z', '/': '7u', '(': '8i', ')': '9o', '=': '0p'\n",
    "    }\n",
    "    # Die Großbuchstaben der Tastaturen auch Berücksichtigen\n",
    "    for k in list(Tasta_Nachbarn.keys()):\n",
    "        Tasta_Nachbarn[k.upper()] = Tasta_Nachbarn[k].upper()\n",
    "\n",
    "    # Function zur Feststellung, ob zwei charchters ähnlich sind\n",
    "    # Characters sind ähnlich wenn sie identical sind (case-insensitive)\n",
    "    # oder Nachbarn auf der Tastatur sind (according to `Tasta_Nachbarn`)\n",
    "    def sim_chk(char1, char2):\n",
    "        # Überprüfen, ob charachters genau übereinstimmen, wenn die Groß-/Kleinschreibung ignoriert wird\n",
    "        if char1.lower() == char2.lower():\n",
    "            return True\n",
    "        # Überprüfen, ob die zweite charachter char2 ein Nachbar von char1 auf der Tastatur ist\n",
    "        if char2 in Tasta_Nachbarn.get(char1, \"\"):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # Function um longest common substring zu berechnen\n",
    "    # die bestimme fehler erlauben\n",
    "    def modified_longest_common_substring(string1, string2):\n",
    "        # beide strings in Kleinbuchstaben umwandeln\n",
    "        string1, string2 = string1.lower(), string2.lower()\n",
    "\n",
    "        # Länge den beiden strings ermittlen um DP tabelle dimentionen zu finden\n",
    "        m, n = len(string1), len(string2)\n",
    "\n",
    "        # 2D-DP-Tabelle initializieren\n",
    "        # Tisch[i][j] will hold the longest common substring length ending at string1[i-1] and string2[j-1]\n",
    "        Tisch = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "        # zum Speichern der langeste gefundenen string\n",
    "        max_len = 0\n",
    "\n",
    "        # Die DP Tabelle füllen\n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, n + 1):\n",
    "                # Aktuelle charchters in string1 und string2\n",
    "                char1, char2 = string1[i - 1], string2[j - 1]\n",
    "\n",
    "                # Wenn charachters genau übereinstimmen, verlängern die substring lenght mit +1 gewischt\n",
    "                if char1 == char2:\n",
    "                    Tisch[i][j] = Tisch[i - 1][j - 1] + 1\n",
    "                    max_len = max(max_len, Tisch[i][j])        # Update max_len if new max is found\n",
    "\n",
    "                # wenn characters sind ähnlich aufgrund der Tastaturnähe oder der Groß-/Kleinschreibung\n",
    "                # erweitern the substring length mit 0.8 gewischt\n",
    "                elif sim_chk(char1, char2):\n",
    "                    Tisch[i][j] = Tisch[i - 1][j - 1] + 0.8\n",
    "\n",
    "                # Behandeln Duplikate, die auf einen Tippfehler zurückzuführen sind\n",
    "                # indem ein wiederholtes charhcter in string1 erkennen das in string2 nicht dupliziert ist, deshalb - 0.2 gewischt\n",
    "                elif i > 1 and string1[i - 1] == string1[i - 2] and (j == 1 or string2[j - 1] != string2[j - 2]):\n",
    "                    Tisch[i][j] = max(Tisch[i][j], Tisch[i - 1][j] - 0.2)\n",
    "\n",
    "                # Behandeln Auslassungen indem die vorherige beste match erweitern\n",
    "                elif i > 1 and Tisch[i - 1][j] > 0:\n",
    "                    Tisch[i][j] = Tisch[i - 1][j] - 0.5\n",
    "                elif j > 1 and Tisch[i][j - 1] > 0:\n",
    "                    Tisch[i][j] = Tisch[i][j - 1] - 0.5\n",
    "\n",
    "                # Behandeln Duplikate, bei denen beide strings dasselbe consecutive characters enthalten wie zB das wort\n",
    "                #'Book' oder 'Cheese' (bzw das ist kein Tippfehler), deshalb sie korrekt/ähnlich sind mit + 1 gewischt\n",
    "                if i > 1 and string1[i - 1] == string1[i - 2] and j > 1 and string2[j - 1] == string2[j - 2]:\n",
    "                    Tisch[i][j] = max(Tisch[i][j], Tisch[i - 2][j - 2] + 1)\n",
    "\n",
    "        # maximale Länge des gefundenen substring zuruckgeben\n",
    "        return max_len\n",
    "\n",
    "    # Die LCS-Länge berechnen\n",
    "    lcs_len = modified_longest_common_substring(string1, string2)\n",
    "\n",
    "    # Normalizierung der LCS Länge durch die kurzen string um similarity score zu berechnen\n",
    "    similarity_score = lcs_len / min(len(string1), len(string2))\n",
    "    out = similarity_score\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qv2OYPPLh3gc",
    "outputId": "7b36a02c-5ca7-4907-8d26-503283a7bda5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('execution', 'execution', 1.0),\n",
       " ('execution', 'intention', 0.4444444444444444),\n",
       " ('inetntion', 'intention', 0.7777777777777778),\n",
       " ('execUtion', 'execution', 1.0),\n",
       " ('exxecution', 'execution', 0.9444444444444444),\n",
       " ('eecution', 'execution', 0.9375),\n",
       " ('execuzion', 'execution', 0.9777777777777779),\n",
       " ('Hunden', 'Hündin', 0.35000000000000003)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests für A1 (Bitte nicht ändern!)\n",
    "\n",
    "testset = [(\"execution\", \"execution\"),\n",
    "  (\"execution\", \"intention\"),\n",
    "  (\"inetntion\", \"intention\"),\n",
    "  (\"execUtion\", \"execution\"),\n",
    "  (\"exxecution\", \"execution\"),\n",
    "  (\"eecution\", \"execution\"),\n",
    "  (\"execuzion\", \"execution\"),\n",
    "  (\"Hunden\", \"Hündin\")]\n",
    "\n",
    "[(i, j, almost_lcs_sim(i, j)) for i, j in testset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSQJmTRLh3gc"
   },
   "source": [
    "Zum Vergleich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQXfR6JWh3gc",
    "outputId": "23464d44-e664-444e-cc4e-6bd7adf0d401"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('execution', 'execution', 1.0),\n",
       " ('execution', 'intention', 0.4444444444444444),\n",
       " ('inetntion', 'intention', 0.5555555555555556),\n",
       " ('execUtion', 'execution', 0.4444444444444444),\n",
       " ('exxecution', 'execution', 0.8888888888888888),\n",
       " ('eecution', 'execution', 0.875),\n",
       " ('execuzion', 'execution', 0.5555555555555556),\n",
       " ('Hunden', 'Hündin', 0.3333333333333333)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, j, lcs_sim(i, j)) for i, j in testset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkCG_WcEh3gc"
   },
   "source": [
    "## Edit Distance (aka Levenshtein Distance)\n",
    "\n",
    "Eine ganz andere Ähnlichkeitseigenschaft von Wortformen ist die **Edit Distance** (Editierdistanz, [Levenshtein Distance](https://de.wikipedia.org/wiki/Levenshtein-Distanz)).\n",
    "\n",
    "### Funktionsweise\n",
    "\n",
    "Die Idee ist, dass es eine kleine Menge von Operationen gibt, nämlich `{insert, delete, substitute, keep}`, die auf Buchstaben angewandt werden können, um ein Wort A in ein Wort B umzuwandeln.\n",
    "\n",
    "Das folgende Beispiel (aus Jurafsky & Martin 2021) stellt eine solche Konversion von *intention* nach *execution* dar:\n",
    "\n",
    "| i | n   | t   | e   | *   | n   | t   | i   | o   | n   |\n",
    "|---|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n",
    "| ↓ | ↓   | ↓   | ↓   | ↓   | ↓   | ↓   | ↓   | ↓   | ↓   |\n",
    "| * | **e** | **x** | **e** | **c** | **u** | **t** | **i** | **o** | **n** |\n",
    "| D | S   | S   |     | I   | S   |     |     |     |     |      |              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9l8g01Dh3gc"
   },
   "source": [
    "Die Konversionsoperationen können dabei unterschiedlich gewichtet werden:\n",
    "- D(elete): 1\n",
    "- S(substitute) : 2\n",
    "- I(nsert): 1\n",
    "- (keep): 0\n",
    "\n",
    "Die Operation S ist deshalb \"teurer\" als D und I, weil hier quasi implizit D und I durchgeführt werden.\n",
    "\n",
    "Aus den angewandten Operationen und deren Gewicht ergibt sich dann, dass die Edit Distance zwischen *intention* und *execution* 8 beträgt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80lSAVLeh3gd"
   },
   "source": [
    "### Minimierung der Edit Distance\n",
    "\n",
    "(im Wesentlichen übernommen aus Jurafsky & Martin 2021)\n",
    "\n",
    "Nun gibt es für zwei Wortformen immer trivialerweise unendlich viele mögliche Werte als Edit Distance – wir können ja beliebig Buchstaben hinzufügen und löschen. Aus diesen möglichen Distanzen interessiert uns aber eigentlich nur die *minimale* Distanz, die sogenannte Minimal Edit Distance oder $D_{Lev}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTdly3Byh3gd"
   },
   "source": [
    "Zur Berechnung von $D_{Lev}$ greift man auf die Methode der **Dynamischen Programmierung** zurück. D.h. man merkt sich Zwischenergebnisse und berechnet nicht für jeden Edit Path alles neu.\n",
    "\n",
    "Dafür wird eine Matrix/Tabelle erstellt, so dass die Buchstaben des einen Worts die Zeilen definieren und die Buchstaben des anderen Worts die Spalten. (Es spielt keine Rolle, welche Wortform in den Spalten und welche Wortform in den Zeilen steht.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8r09VAjh3gd"
   },
   "source": [
    "Nehmen wir im Folgenden an, dass $w_1 =$ *execution* und $w_2 =$ *intention*. Das jeweils erste Zeichen ist das leere Zeichen \\# und die Tabelle wird in der Zelle $[1,1]$ mit $0$ initialisiert.  \n",
    "\n",
    "|       | \\# | e | x | e | c | u | t | i | o | n |\n",
    "|-------|----|---|---|---|---|---|---|---|---|---|\n",
    "| \\#    |  0 |   |   |   |   |   |   |   |   |   |\n",
    "| **i** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **n** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **t** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **e** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **n** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **t** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **i** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **o** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **n** |    |   |   |   |   |   |   |   |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nVT3oK7h3gd"
   },
   "source": [
    "Im Anschluss wird die Tabelle von $[1,1]$ bis $[|w_1|+1,|w_2|+1]$ anhand der rekursiven Funktion $D$ ausgefüllt:\n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "D(x,y) = min ( & D(x-1,y) + \\text{del-cost},\\\\\n",
    "& D(x,y-1) + \\text{ins-cost},\\\\\n",
    "& D(x-1,y-1) + \\text{subst-cost},\\\\\n",
    "& D(x-1,y-1) ~\\mathit{iff}~ w_1[x]=w_2[y])\n",
    "\\end{array}$$\n",
    "\n",
    "Dabei soll gelten:\n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "\\text{del-cost} = 1\\\\\n",
    "\\text{ins-cost} = 1\\\\\n",
    "\\text{subst-cost} = 2\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKfqBlWLh3gd"
   },
   "source": [
    "Wir erhalten schließlich die folgende vollständig ausgefüllte Tabelle:\n",
    "\n",
    "|       | \\#  | e   | x   | e    | c    | u    | t    | i    | o    | n    |\n",
    "|-------|-----|-----|-----|------|------|------|------|------|------|------|\n",
    "| \\#    | <span style=\"color:red\">0</span> | 1 | 2 | 3  | 4  | 5  | 6  | 7  | 8  | 9  |\n",
    "| **i** | <span style=\"color:red\">1</span> | 2 | 3 | 4  | 5  | 6  | 7  | 6  | 7  | 8  |\n",
    "| **n** | 2 | <span style=\"color:red\">3</span> | 4 | 5  | 6  | 7  | 8  | 7  | 8  | 7  |\n",
    "| **t** | 3 | 4 | <span style=\"color:red\">5</span> | 6  | 7  | 8  | 7  | 8  | 9  | 8  |\n",
    "| **e** | 4 | 3 | 4 | <span style=\"color:red\">5</span>  | <span style=\"color:red\">6</span>  | 7  | 8  | 9  | 10 | 9  |\n",
    "| **n** | 5 | 4 | 5 | 6  | 7  | <span style=\"color:red\">8</span>  | 9  | 10 | 11 | 10 |\n",
    "| **t** | 6 | 5 | 6 | 7  | 8  | 9  | <span style=\"color:red\">8</span>  | 9  | 10 | 11 |\n",
    "| **i** | 7 | 6 | 7 | 8  | 9  | 10 | 9  | <span style=\"color:red\">8</span>  | 9  | 10 |\n",
    "| **o** | 8 | 7 | 8 | 9  | 10 | 11 | 10 | 9  | <span style=\"color:red\">8</span>  | 9  |\n",
    "| **n** | 9 | 8 | 9 | 10 | 11 | 12 | 11 | 10 | 9  | <span style=\"color:red\">8</span>  |\n",
    "\n",
    "$D_{Lev}(w_1,w_2)$ ist dann der Inhalt der Zelle $[|w_1|+1,|w_2|+1]$, also $8$. Die rot hervorgehobenen Zellen stellen einen Minimal-Edit-Pfad dar, den man anhand der Backtraces rekonstruieren kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgVzX6Ggh3gd"
   },
   "source": [
    "### Edit Distance in NLTK\n",
    "\n",
    "NLTK stellt die entsprechende Funktion `edit_distance(s1,s2)` im Modul [`metrics`](https://www.nltk.org/api/nltk.metrics.html#module-nltk.metrics.distance) zur Verfügung.\n",
    "\n",
    "Die Gewichtung der Substitutionsoperation kann mittels des Parameters `substitution_cost` spezifiziert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3prLWtN6h3gd",
    "outputId": "c024959d-b2c7-46a8-ca55-81efc5454f1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('execution', 'execution', 0),\n",
       " ('execution', 'intention', 8),\n",
       " ('inetntion', 'intention', 2),\n",
       " ('execUtion', 'execution', 2),\n",
       " ('exxecution', 'execution', 1),\n",
       " ('eecution', 'execution', 1),\n",
       " ('execuzion', 'execution', 2),\n",
       " ('Hunden', 'Hündin', 4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.metrics import edit_distance\n",
    "\n",
    "[(i, j, edit_distance(i, j, substitution_cost=2)) for i, j in testset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCS3oJN0h3gd"
   },
   "source": [
    "Wieder kann die Ähnlichkeitseigenschaft mittels der Länge der kleineren Wortform gewichtet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MdLXthth3gd",
    "outputId": "68d1b857-9c63-494e-d972-e4d3af36bb13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('execution', 'execution', 1.0),\n",
       " ('execution', 'intention', 0.4444444444444444),\n",
       " ('inetntion', 'intention', 0.7777777777777778),\n",
       " ('execUtion', 'execution', 0.8888888888888888),\n",
       " ('exxecution', 'execution', 0.8888888888888888),\n",
       " ('eecution', 'execution', 0.875),\n",
       " ('execuzion', 'execution', 0.8888888888888888),\n",
       " ('Hunden', 'Hündin', 0.6666666666666667)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lev_sim(string1, string2):\n",
    "    return 1 - edit_distance(string1, string2) / len(min(string1, string2))\n",
    "\n",
    "\n",
    "[(i, j, lev_sim(i, j)) for i, j in testset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qko6m9sxh3gd"
   },
   "source": [
    "# Rechtschreibkorrektur mit Edit Distance und dem Brown Corpus\n",
    "\n",
    "Mit Hilfe der Edit Distance ist es recht einfach, ein Programm zu schreiben, das Vorschläge zur Rechtschreibkorrektur machen kann. Man braucht dafür im Grunde nur noch eine Liste mit Wortformen, die als Korrektur vorgeschlagen werden sollen.\n",
    "\n",
    "Die Wortformenliste können wir einfach aus den Worttoken im Brown Corpus generieren. Außerdem nutzen wir eine Funktion `propose_word_corrections()`, die für einen Eingabestring diejenigen Wortformen aus einer Wortformenliste ausgibt, die maximal eine bestimmte Edit Distance (`edt`) zum Eingabestring haben. Als Funktion zur Ermittlung der Edit Distance dient uns diesmal `edit_distance()` aus NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auE4Us5fR48i",
    "outputId": "81fc67e2-db41-488b-c01b-670f290319bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BWdURQ9sh3ge"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "brownWords = set(brown.words())\n",
    "\n",
    "\n",
    "def propose_word_corrections(string, edt, lexicon):\n",
    "    return [word for word in lexicon if edit_distance(word, string) <= edt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp9Y44rBh3ge"
   },
   "source": [
    "Mit `propose_word_corrections()` erhalten wir relativ zügig sinnvolle Vorschläge zur Rechtschreibkorrektur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A985Pv1Lh3ge",
    "outputId": "60a1188a-6108-40f0-edcd-5594680faa16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['invention', 'intention']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propose_word_corrections(\"inetntion\", 2, brownWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY_hdVf9h3ge"
   },
   "source": [
    "Was nun noch stört, ist die Edit Distance Threshold `edt`. Wie könnte die automatisch gesetzt werden?\n",
    "\n",
    "## <span style=\"color:red\">Aufgaben II</span>\n",
    "\n",
    "<span style=\"color:red\">A2:</span> Implementieren Sie eine Funktion `lazy_propose_word_corrections(string,lexicon)`, die `edt` automatisch (und möglichst sinnvoll) anhand der Eingabe und der Ausgabe festlegt. Führen Sie damit den anschließenden Test aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BFVSSVdbh3ge"
   },
   "outputs": [],
   "source": [
    "# Lösung A2\n",
    "\n",
    "def lazy_propose_word_corrections (string,lexicon) :\n",
    "  # „edt“ auf der Grundlage der Länge der input string definieren\n",
    "    if len(string) <= 3:\n",
    "        edt = 1\n",
    "    elif len(string) <= 6:       # Diese Werte habe ich nach mehreren Versuch/Irrtum-Experimenten gewählt\n",
    "        edt = 1\n",
    "    elif len(string) <= 10:\n",
    "        edt = 2\n",
    "    else:\n",
    "        edt = 3    # Für längere strings\n",
    "\n",
    "    # Wörter aus dem Lexikon zurückgeben, die innerhalb der berechneten Edit distance liegen\n",
    "    return [word for word in lexicon if edit_distance(word, string) <= edt]\n",
    "    #return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omxOXEZmh3ge"
   },
   "source": [
    "Test von `lazy_propose_word_corrections()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kl345xc-h3ge",
    "outputId": "4149c3b0-af33-4f28-abe7-f3641bc6c0fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['invention', 'intention']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_propose_word_corrections(\"inetntion\",brownWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLYqUW3bh3ge"
   },
   "source": [
    "# Probleme und Verbesserungsmöglichkeiten\n",
    "\n",
    "## Umfang der Wortformenliste\n",
    "\n",
    "Die Korrekturvorschläge werden auf Grundlage einer Wortformenliste gemacht. Diese Wortformenliste sollte im Idealfall alle korrekt geschriebenen Worte einer Sprache enthalten. Oben haben wir dafür das Brown Corpus verwendet und für das Englische war das bereits eine gute Approximation.\n",
    "\n",
    "Für eine Sprache wie das Deutsche gestaltet sich das aber schwieriger wegen der reichaltigeren Flexion und der Möglichkeit, Komposita ohne Leerzeichen zu bilden (*Eiersalatsoßengewürz*). Dadurch ist die Anzahl der Wortformen im Deutschen *wesentlich* höher als im Englischen.\n",
    "\n",
    "Heutzutage scheint das kein Problem mehr zu sein, denn man kann einfach ein riesigs Webcorpus nehmen (z.B. enthält [DeReKo](https://www.ids-mannheim.de/digspra/kl/projekte/korpora/) mehr als 50 Milliarden Token), in dem Millionen von Wortformen enthalten sind. Das Problem ist aber dann, dass solche Ressourcen auch sehr untypische Wortformen enthalten, was die Korrekturhilfe einerseits zu tolerant macht und andererseits zu sehr vielen nutzlosen Vorschlägen führen kann. Und bestimmte Komposita werden auch dort nicht enthalten sein.\n",
    "\n",
    "Ein Lösungsansatz besteht darin, mehrstufig vorzugehen: Die Komposita werden zuerst getrennt und dann überprüft.\n",
    "\n",
    "Außerdem kann die Häufigkeit einer Wortform im Corpus verwendet werden, um die Liste der Korrekturvorschläge klein und möglichst sinnvoll zu halten.\n",
    "\n",
    "## Geschwindigkeit\n",
    "\n",
    "Der Umfang der Wortliste hat auch einen Einfluss auf die Geschwindigkeit der Rechtschreibkorrektur. Wenn so wie bei der  Funktion `propose_word_corrections()` die Edit Distance zu allen Wortformen der Wortliste einzeln berechnet wird, wird sich das auf die Geschwindigkeit gerade bei umfangreiche Wortlisten spürbar auswirken. Die Wortliste muss also irgendwie stärker strukturiert werden, um den Suchbereich sinnvoll einzugrenzen.\n",
    "\n",
    "Zudem könnte man die Berechnung der Edit Distance früher abbrechen, wenn ein Schwellenwert bekannt ist und aus dem Durchlauf der Tabelle klar wird, dass dieser nicht mehr erreicht oder unterboten werden kann.\n",
    "\n",
    "## Kontextabhängigkeit\n",
    "\n",
    "Wortformen wie *dass* und *das* sind nicht an allen Positionen im Satz gleich gut. Ein \"intelligenter\" Rechtschreibkorrektor würde erkennen, dass *das* an der Stelle einer Konjunktion (*dass*, *weil*, *nachdem*, ...) falsch geschrieben ist. Dafür brauchen wir Informationen zum POS-Tag oder Informationen zum Kontext in einem Satz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEA9N4LNh3gf"
   },
   "source": [
    "## Editieroperationen und deren Gewichte\n",
    "\n",
    "Um die Qualität der Rechtschreibkorrektur zu erhöhen, können weitere Editieroperationen hinzugefügt und deren Gewichte optimiert werden.\n",
    "\n",
    "Wir haben z.B. oben schon gesehen, dass Subsitution mal mit 1 und mal mit 2 gewichtet wird. Außerdem könnte man sich überlegen, die Gewichtung abhängig von der relativen Position auf der Tastatur festzulegen: Wenn wir eine Substitution von zwei Buchstaben wie *i* und *o* haben, dann sollte das geringer gewichtet werden als eine Substitution von *i* und *s*. Leider ist es gar nicht so trivial, die Gewichte relativ zueinander optimal festzulegen. Man wird hier wohl sehr viele Testdurchläufe brauchen (siehe unten) ...\n",
    "\n",
    "Was die Editieroperationen betrifft, stellt `edit_distance()` zusätzlich noch die **Transposition** zur Verfügung. Diese Operationen fasst im Grunde eine Deletion und eine Insertion zusammen und ist damit der Substitution sehr ähnlich:\n",
    "\n",
    "- *in**et**ntion* $\\Rightarrow$ *in**te**ntion*\n",
    "\n",
    "Bei `edit_distance()` kann die Transposition mit dem Argument `transpositions=True` aktiviert werden und wird dann mit 1 gewichtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQNueVIRh3gf",
    "outputId": "10350e59-0649-4cad-e47f-dfdcf1a16c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without transpositions: 2\n",
      "with transpositions: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"without transpositions: \" + str(edit_distance(\"inetntion\",\"intention\")))\n",
    "print(\"with transpositions: \"    + str(edit_distance(\"inetntion\",\"intention\",transpositions=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJeDu3f6h3gf"
   },
   "source": [
    "Es sind natürlich noch weitere Editieroperationen denkbar. Z.B. wäre es manchmal hilfreich, ein Leerzeichen einfügen zu können.\n",
    "\n",
    "- *allright* $\\Rightarrow$ *all right*\n",
    "\n",
    "Ein nützliches Kriterium kann außerdem die [graphophonologische Ähnlichkeit](http://aspell.net/metaphone/) sein:\n",
    "\n",
    "- *taff* $\\Rightarrow$ *tough*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHlMfBpGh3gf"
   },
   "source": [
    "# Evaluation durch Testdaten\n",
    "\n",
    "Wir haben bis hierhin gesehen, dass es eine Reihe von Parametern (Ähnlichkeitseigenschaften, Editieroperationen, Gewichte, Wortliste, ...) gibt, die man bei der Implementierung einer Rechtschreibkorrektur festlegen muss. Die Frage ist, wie man das so machen kann, dass die Zielgrößen optimiert werden, nämlich:\n",
    "- niedriger Ressourcenverbrauch: Zeit, Strom, Speicher\n",
    "- hohe [Präzision](https://en.wikipedia.org/wiki/Precision_and_recall): $P = \\frac{tp}{tp+fp}$\n",
    "- hoher [Recall](https://en.wikipedia.org/wiki/Precision_and_recall): $R = \\frac{tp}{tp+fn}$\n",
    "- hohes [F1-Maß](https://en.wikipedia.org/wiki/F1_score): $F = \\frac{2*P*R}{P+R}$\n",
    "\n",
    "Außerdem müssen wir die Zielgrößen anhand konkreter Daten, dem sogenannten **Testset**, überprüfen. Es reicht nicht zu sagen: \"Ich glaube aber, dass diese Parameter besser sind.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-trJ7XPh3gf"
   },
   "source": [
    "Tatsächlich wirft jedoch der Bedarf eines Testsets eine weitere nichttriviale Frage auf: Wie können wir ein Testset so zusammenstellen, dass die Qualität der Rechtschreibkorrektur *realistischerweise* gemessen werden kann. Tatsächlich erfordert das ein nicht unerhebliches Wissen hinsichtlich der Morphophonologie, der Tippergonomie, der typischen Fehler und der Erwartungshaltung der Nutzer ...\n",
    "\n",
    "Wir werden im Folgenden die Qualität unserer Rechtschreibkorrektoren anhand eines Testsets überprüfen. Als Testset verwenden wir das Testset von Aspell ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0_y8MbAh3gf"
   },
   "source": [
    "## <span style=\"color:red\">Aufgaben III</span>\n",
    "\n",
    "<span style=\"color:red\">A3:</span> Laden Sie das Testset von Aspell (http://aspell.net/test/cur/batch0.tab) herunter und verändern Sie die folgende Funktion `TEST_propose_word_corrections()` so, dass für eine Eingabe `s1` eine möglichst gute Korrekturliste hinsichtlich des F1-Maßes ausgegeben wird. Testen Sie anschließend die generierten Korrekturlisten mit dem darunter stehenden Skript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ViIATwT9iNYG"
   },
   "outputs": [],
   "source": [
    "#### Der Vorgang mit dem Code dauert ca 57 Minuten ####     Recall: 0.6197; Precision: 0.124: F1-score: 0.2073\n",
    "\n",
    "# Ich habe viele Strategien ausprobiert, die keine maschinelle Klassifikation oder vorab trainierte Sprachmodelle verwenden (da dies anscheinend nicht der Zweck dieser Aufgabe ist),\n",
    "# um die Parameter zu verbessern/abzustimmen, die den besten F1-Score ergeben. Zu diesen Strategien gehörte das Filtern von Wörtern im Brown Corpus basierend auf dynamisch bestimmten Worthäufigkeiten\n",
    "# und anschließend die Bewertung auf Grundlage einer Kombination aus dynamisch angepasster gewichteter Editierdistanz und gewichteter Häufigkeit.\n",
    "# Dies sollte sicherstellen, dass die endgültige Liste die besten 5 oder 10 Korrekturen basierend auf Editierdistanz und Häufigkeit enthält.\n",
    "# Ich hoffte, dass dies den F1-Score erhöhen würde. Es gelang mir, die Recall- und Precision-Werte zu verbessern, aber ich erreichte nie einen F1-Score von mehr als 0.2!\n",
    "# Ein signifikant limitierender Faktor in dieser Aufgabe war die Rechenzeit. Die kürzeste war 18 Minuten und die längste 57 Minuten für die verschiedenen Ansätze,\n",
    "# die ich versucht habe, um einen guten F1-Score zu erreichen.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def TEST_propose_word_corrections(s1):\n",
    "    out = []\n",
    "\n",
    "    # Worthäufigkeiten im Brown Corpus zahlen\n",
    "    word_freq = Counter(brownWords)  # Ensure brownWords is a list of words from the Brown Corpus\n",
    "\n",
    "    # edit distance basierend auf der Wortlänge anpassen\n",
    "    if len(s1) <= 3:\n",
    "        edt = [1, 2, 3]\n",
    "    elif len(s1) <= 6:\n",
    "        edt = [1, 2, 3, 4]\n",
    "    elif len(s1) <= 10:\n",
    "        edt = [2, 3, 4, 5]\n",
    "    else:\n",
    "        edt = [3, 4, 5, 6]\n",
    "\n",
    "    # Set Initialisieren, der alle vorgeschlagenen Korrekturen enthält Initialisieren\n",
    "    all_proposed_corrections = set()\n",
    "\n",
    "    # Initialize frequency threshold for the Brown Corpus\n",
    "    min_freq = 2  # Start with a low frequency threshold to allow rare words\n",
    "\n",
    "    # über alle möglichen edit distance Iterieren\n",
    "    for edit in edt:\n",
    "        # Filtern von Wörtern aus Brown Corpus mit ausreichender Häufigkeit\n",
    "        filtered_words = [w for w in brownWords if word_freq[w] >= min_freq]\n",
    "\n",
    "        # Kandidatenkorrekturen mit der vorhandenen Funktion \"propose_word_corrections\" Generieren\n",
    "        proposedCorrections = propose_word_corrections(s1, edit, filtered_words)\n",
    "        all_proposed_corrections.update(proposedCorrections)\n",
    "\n",
    "        # frequency threshold dynamisches Anpassen, wenn keine Kandidaten gefunden werden\n",
    "        if not proposedCorrections and min_freq > 1:\n",
    "            min_freq -= 1  # Gradually lower the threshold if no matches are found\n",
    "\n",
    "        # Vorzeitiges Stoppen, wenn genügend Korrekturen gefunden wurden (Um unnecessary computation zu vermeiden)\n",
    "        if len(all_proposed_corrections) >= 5:\n",
    "            break\n",
    "\n",
    "    # Dynamisches Anpassen der Gewichtung basierend auf length of the input word\n",
    "    edit_weight = 1           # Grundgewicht for edit distance\n",
    "    freq_weight = 0.1         # Grundgewicht for frequency in the Brown Corpus\n",
    "\n",
    "    # die Gewichtung für den Edit distance dynamisch basierend auf der Wortlänge anpassen\n",
    "    if len(s1) <= 3:\n",
    "        edit_weight = 0.8   # Kurze Wörter haben eine geringere Gewichtung der Edit distance\n",
    "    elif len(s1) <= 6:\n",
    "        edit_weight = 1     # Medium-length words get a normal edit distance weight\n",
    "    elif len(s1) <= 10:\n",
    "        edit_weight = 1.2   # Längere Wörter benötigen möglicherweise etwas mehr Gewicht für den edit distance\n",
    "    else:\n",
    "        edit_weight = 1.5   # Sehr lange Wörter benötigen möglicherweise mehr Gewicht für den edit distance\n",
    "\n",
    "    # die Gewichtung für die Häufigkeit basierend auf der Häufigkeit des Wortes im Brown corpus anpassen\n",
    "    if word_freq[s1] > 10:        # Wenn das Wort sehr häufig im Korpus vorkommt, mehr Wert auf die Frequenz legen\n",
    "        freq_weight = 0.2\n",
    "    elif word_freq[s1] > 5:\n",
    "        freq_weight = 0.15\n",
    "    else:\n",
    "        freq_weight = 0.1        # seltenen Wörtern eine kleinere Gewichtung für die Häufigkeit geben\n",
    "\n",
    "    # die gewichtete Sortierung nach edit distance und -häufigkeit anwenden\n",
    "    # von Kandidaten sowohl nach edit distance als auch nach Häufigkeit sortieren\n",
    "    sorted_corrections = sorted(\n",
    "        all_proposed_corrections,\n",
    "        key=lambda w: (edit_distance(s1, w) * edit_weight) - (word_freq[w] * freq_weight)\n",
    "    )\n",
    "\n",
    "    # Top Kandidaten\n",
    "    top_n = 5\n",
    "    out.extend(sorted_corrections[:top_n])\n",
    "\n",
    "    return out\n",
    "\n",
    "###############\n",
    "# Work directory festlegen\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(current_dir)\n",
    "print(\"Mein aktuelles working directory:\", os.getcwd())\n",
    "\n",
    "# \"batch0.tab\" Herunterladen\n",
    "import urllib.request\n",
    "url = \"http://aspell.net/test/cur/batch0.tab\"\n",
    "filename = \"batch0.tab\"\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "print(f\"Downloaded {filename}\")\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zLkkdiQh3gf"
   },
   "source": [
    "Evaluation der Funktion `TEST_propose_word_corrections` – Achtung, es kann mehrere Minuten dauern, bis alle 547 Paare verarbeitet sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1Tdn-Duh3gf",
    "outputId": "e6ec1e47-c6c4-4821-d2ae-7f7753711b41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test word           Gold correction     Gold in candidates  Size of candidate list\n",
      "----------------------------------------------------------------------------------\n",
      "Accosinly           Occasionally        FALSE               5                   \n",
      "Ciculer             Circler             FALSE               5                   \n",
      "Circue              Circle              TRUE                5                   \n",
      "Maddness            Madness             FALSE               5                   \n",
      "Occusionaly         Occasionally        TRUE                5                   \n",
      "Steffen             Stephen             TRUE                5                   \n",
      "Thw                 The                 TRUE                5                   \n",
      "Unformanlly         Unfortunately       FALSE               5                   \n",
      "Unfortally          Unfortunately       FALSE               5                   \n",
      "abilitey            ability             TRUE                5                   \n",
      "abouy               about               TRUE                5                   \n",
      "absorbtion          absorption          TRUE                5                   \n",
      "accidently          accidentally        TRUE                5                   \n",
      "accomodate          accommodate         TRUE                5                   \n",
      "acommadate          accommodate         TRUE                5                   \n",
      "acord               accord              TRUE                5                   \n",
      "adultry             adultery            TRUE                5                   \n",
      "aggresive           aggressive          TRUE                5                   \n",
      "alchohol            alcohol             TRUE                5                   \n",
      "alchoholic          alcoholic           TRUE                5                   \n",
      "allieve             alive               TRUE                5                   \n",
      "alot                a lot               FALSE               5                   \n",
      "alright             all right           FALSE               5                   \n",
      "amature             amateur             FALSE               5                   \n",
      "ambivilant          ambivalent          TRUE                5                   \n",
      "amification         amplification       TRUE                5                   \n",
      "amourfous           amorphous           TRUE                5                   \n",
      "annoint             anoint              FALSE               5                   \n",
      "annonsment          announcement        TRUE                5                   \n",
      "annoyting           anting              FALSE               5                   \n",
      "annuncio            announce            TRUE                5                   \n",
      "anonomy             anatomy             TRUE                5                   \n",
      "anotomy             anatomy             TRUE                5                   \n",
      "antidesestablishmentarianismantidisestablishmentarianismFALSE               0                   \n",
      "antidisestablishmentarismantidisestablishmentarianismFALSE               0                   \n",
      "anynomous           anonymous           TRUE                5                   \n",
      "appelet             applet              FALSE               5                   \n",
      "appreceiated        appreciated         TRUE                5                   \n",
      "appresteate         appreciate          TRUE                5                   \n",
      "aquantance          acquaintance        TRUE                5                   \n",
      "aratictature        architecture        TRUE                5                   \n",
      "archeype            archetype           FALSE               5                   \n",
      "aricticure          architecture        FALSE               5                   \n",
      "artic               arctic              FALSE               5                   \n",
      "asentote            asymptote           FALSE               5                   \n",
      "ast                 at                  FALSE               5                   \n",
      "asterick            asterisk            FALSE               5                   \n",
      "asymetric           asymmetric          TRUE                5                   \n",
      "atentively          attentively         TRUE                5                   \n",
      "autoamlly           automatically       FALSE               5                   \n",
      "bankrot             bankrupt            TRUE                5                   \n",
      "basicly             basically           TRUE                5                   \n",
      "batallion           battalion           TRUE                5                   \n",
      "bbrose              browse              FALSE               5                   \n",
      "beauro              bureau              FALSE               5                   \n",
      "beaurocracy         bureaucracy         TRUE                5                   \n",
      "beggining           beginning           TRUE                5                   \n",
      "beging              beginning           FALSE               5                   \n",
      "behaviour           behavior            TRUE                5                   \n",
      "beleive             believe             TRUE                5                   \n",
      "belive              believe             TRUE                5                   \n",
      "benidifs            benefits            TRUE                5                   \n",
      "bigginging          beginning           TRUE                5                   \n",
      "blait               bleat               FALSE               5                   \n",
      "bouyant             buoyant             TRUE                5                   \n",
      "boygot              boycott             TRUE                5                   \n",
      "brocolli            broccoli            TRUE                5                   \n",
      "buch                bush                TRUE                5                   \n",
      "buder               butter              FALSE               5                   \n",
      "budr                butter              FALSE               5                   \n",
      "budter              butter              TRUE                5                   \n",
      "buracracy           bureaucracy         TRUE                5                   \n",
      "burracracy          bureaucracy         TRUE                5                   \n",
      "buton               button              TRUE                5                   \n",
      "byby                by by               FALSE               5                   \n",
      "cauler              caller              TRUE                5                   \n",
      "ceasar              caesar              FALSE               5                   \n",
      "cemetary            cemetery            TRUE                5                   \n",
      "changeing           changing            TRUE                5                   \n",
      "cheet               cheat               TRUE                5                   \n",
      "cicle               circle              TRUE                5                   \n",
      "cimplicity          simplicity          TRUE                5                   \n",
      "circumstaces        circumstances       TRUE                5                   \n",
      "clob                club                TRUE                5                   \n",
      "coaln               colon               FALSE               5                   \n",
      "cocamena            cockamamie          FALSE               5                   \n",
      "colleaque           colleague           TRUE                5                   \n",
      "colloquilism        colloquialism       FALSE               5                   \n",
      "columne             column              TRUE                5                   \n",
      "comiler             compiler            TRUE                5                   \n",
      "comitmment          commitment          TRUE                5                   \n",
      "comitte             committee           TRUE                5                   \n",
      "comittmen           commitment          TRUE                5                   \n",
      "comittmend          commitment          TRUE                5                   \n",
      "commerciasl         commercials         TRUE                5                   \n",
      "commited            committed           TRUE                5                   \n",
      "commitee            committee           TRUE                5                   \n",
      "companys            companies           TRUE                5                   \n",
      "compicated          complicated         TRUE                5                   \n",
      "comupter            computer            TRUE                5                   \n",
      "concensus           consensus           TRUE                5                   \n",
      "confusionism        confucianism        FALSE               5                   \n",
      "congradulations     congratulations     TRUE                5                   \n",
      "conibation          contribution        FALSE               5                   \n",
      "consident           consistent          TRUE                5                   \n",
      "consident           consonant           FALSE               5                   \n",
      "contast             constant            FALSE               5                   \n",
      "contastant          constant            TRUE                5                   \n",
      "contunie            continue            TRUE                5                   \n",
      "cooly               coolly              TRUE                5                   \n",
      "copping             coping              FALSE               5                   \n",
      "cosmoplyton         cosmopolitan        TRUE                5                   \n",
      "courst              court               TRUE                5                   \n",
      "crasy               crazy               TRUE                5                   \n",
      "cravets             caveats             FALSE               5                   \n",
      "credetability       credibility         TRUE                5                   \n",
      "criqitue            critique            TRUE                5                   \n",
      "croke               croak               FALSE               5                   \n",
      "crucifiction        crucifixion         TRUE                5                   \n",
      "crusifed            crucified           TRUE                5                   \n",
      "ctitique            critique            TRUE                5                   \n",
      "cumba               combo               FALSE               5                   \n",
      "custamisation       customization       FALSE               5                   \n",
      "dag                 dog                 FALSE               5                   \n",
      "daly                daily               TRUE                5                   \n",
      "danguages           dangerous           FALSE               5                   \n",
      "deaft               draft               TRUE                5                   \n",
      "defence             defense             TRUE                5                   \n",
      "defenly             defiantly           FALSE               5                   \n",
      "definate            definite            TRUE                5                   \n",
      "definately          definitely          TRUE                5                   \n",
      "dependeble          dependable          TRUE                5                   \n",
      "descrption          description         TRUE                5                   \n",
      "descrptn            description         TRUE                5                   \n",
      "desparate           desperate           TRUE                5                   \n",
      "dessicate           desiccate           FALSE               5                   \n",
      "destint             distant             TRUE                5                   \n",
      "develepment         developments        TRUE                5                   \n",
      "developement        development         TRUE                5                   \n",
      "develpond           development         FALSE               5                   \n",
      "devulge             divulge             FALSE               5                   \n",
      "diagree             disagree            TRUE                5                   \n",
      "dieties             deities             TRUE                5                   \n",
      "dinasaur            dinosaur            TRUE                5                   \n",
      "dinasour            dinosaur            TRUE                5                   \n",
      "direcyly            directly            TRUE                5                   \n",
      "discuess            discuss             TRUE                5                   \n",
      "disect              dissect             FALSE               5                   \n",
      "disippate           dissipate           FALSE               5                   \n",
      "disition            decision            FALSE               5                   \n",
      "dispair             despair             TRUE                5                   \n",
      "disssicion          discussion          FALSE               5                   \n",
      "distarct            distract            TRUE                5                   \n",
      "distart             distort             TRUE                5                   \n",
      "distroy             destroy             TRUE                5                   \n",
      "documtations        documentation       TRUE                5                   \n",
      "doenload            download            FALSE               5                   \n",
      "dongle              dangle              TRUE                5                   \n",
      "doog                dog                 TRUE                5                   \n",
      "dramaticly          dramatically        TRUE                5                   \n",
      "drunkeness          drunkenness         TRUE                5                   \n",
      "ductioneery         dictionary          TRUE                5                   \n",
      "dur                 due                 FALSE               5                   \n",
      "duren               during              FALSE               5                   \n",
      "dymatic             dynamic             TRUE                5                   \n",
      "dynaic              dynamic             TRUE                5                   \n",
      "ecstacy             ecstasy             TRUE                5                   \n",
      "efficat             efficient           FALSE               5                   \n",
      "efficity            efficacy            TRUE                5                   \n",
      "effots              efforts             TRUE                5                   \n",
      "egsistence          existence           TRUE                5                   \n",
      "eitiology           etiology            FALSE               5                   \n",
      "elagent             elegant             FALSE               5                   \n",
      "elligit             elegant             FALSE               5                   \n",
      "embarass            embarrass           FALSE               5                   \n",
      "embarassment        embarrassment       TRUE                5                   \n",
      "embaress            embarrass           FALSE               5                   \n",
      "encapsualtion       encapsulation       FALSE               5                   \n",
      "encyclapidia        encyclopedia        TRUE                5                   \n",
      "encyclopia          encyclopedia        TRUE                5                   \n",
      "engins              engine              TRUE                5                   \n",
      "enhence             enhance             TRUE                5                   \n",
      "enligtment          Enlightenment       FALSE               5                   \n",
      "ennuui              ennui               FALSE               5                   \n",
      "enought             enough              TRUE                5                   \n",
      "enventions          inventions          TRUE                5                   \n",
      "envireminakl        environmental       TRUE                5                   \n",
      "enviroment          environment         TRUE                5                   \n",
      "epitomy             epitome             TRUE                5                   \n",
      "equire              acquire             FALSE               5                   \n",
      "errara              error               TRUE                5                   \n",
      "erro                error               TRUE                5                   \n",
      "evaualtion          evaluation          TRUE                5                   \n",
      "evething            everything          TRUE                5                   \n",
      "evtually            eventually          TRUE                5                   \n",
      "excede              exceed              FALSE               5                   \n",
      "excercise           exercise            TRUE                5                   \n",
      "excpt               except              TRUE                5                   \n",
      "excution            execution           TRUE                5                   \n",
      "exhileration        exhilaration        FALSE               5                   \n",
      "existance           existence           TRUE                5                   \n",
      "expleyly            explicitly          FALSE               5                   \n",
      "explity             explicitly          FALSE               5                   \n",
      "expresso            espresso            FALSE               5                   \n",
      "exspidient          expedient           TRUE                5                   \n",
      "extions             extensions          FALSE               5                   \n",
      "factontion          factorization       FALSE               5                   \n",
      "failer              failure             FALSE               5                   \n",
      "famdasy             fantasy             TRUE                5                   \n",
      "faver               favor               TRUE                5                   \n",
      "faxe                fax                 FALSE               5                   \n",
      "febuary             february            FALSE               5                   \n",
      "firey               fiery               FALSE               5                   \n",
      "fistival            festival            TRUE                5                   \n",
      "flatterring         flattering          TRUE                5                   \n",
      "fluk                flux                TRUE                5                   \n",
      "flukse              flux                FALSE               5                   \n",
      "fone                phone               FALSE               5                   \n",
      "forsee              foresee             TRUE                5                   \n",
      "frustartaion        frustrating         FALSE               5                   \n",
      "fuction             function            TRUE                5                   \n",
      "funetik             phonetic            FALSE               5                   \n",
      "futs                guts                TRUE                5                   \n",
      "gamne               came                FALSE               5                   \n",
      "gaurd               guard               FALSE               5                   \n",
      "generly             generally           FALSE               5                   \n",
      "ghandi              gandhi              FALSE               5                   \n",
      "goberment           government          TRUE                5                   \n",
      "gobernement         government          TRUE                5                   \n",
      "gobernment          government          TRUE                5                   \n",
      "gotton              gotten              TRUE                5                   \n",
      "gracefull           graceful            TRUE                5                   \n",
      "gradualy            gradually           TRUE                5                   \n",
      "grammer             grammar             TRUE                5                   \n",
      "hallo               hello               TRUE                5                   \n",
      "hapily              happily             TRUE                5                   \n",
      "harrass             harass              TRUE                5                   \n",
      "havne               have                TRUE                5                   \n",
      "heellp              help                FALSE               5                   \n",
      "heighth             height              TRUE                5                   \n",
      "hellp               help                TRUE                5                   \n",
      "helo                hello               FALSE               5                   \n",
      "herlo               hello               TRUE                5                   \n",
      "hifin               hyphen              FALSE               5                   \n",
      "hifine              hyphen              FALSE               5                   \n",
      "higer               higher              TRUE                5                   \n",
      "hiphine             hyphen              FALSE               5                   \n",
      "hippie              hippy               FALSE               5                   \n",
      "hippopotamous       hippopotamus        FALSE               3                   \n",
      "hlp                 help                TRUE                5                   \n",
      "hourse              horse               FALSE               5                   \n",
      "houssing            housing             TRUE                5                   \n",
      "howaver             however             TRUE                5                   \n",
      "howver              however             TRUE                5                   \n",
      "humaniti            humanity            TRUE                5                   \n",
      "hyfin               hyphen              FALSE               5                   \n",
      "hypotathes          hypothesis          FALSE               5                   \n",
      "hypotathese         hypothesis          TRUE                5                   \n",
      "hystrical           hysterical          TRUE                5                   \n",
      "ident               indent              FALSE               5                   \n",
      "illegitament        illegitimate        TRUE                5                   \n",
      "imbed               embed               FALSE               5                   \n",
      "imediaetly          immediately         TRUE                5                   \n",
      "imfamy              infamy              TRUE                5                   \n",
      "immenant            immanent            TRUE                5                   \n",
      "implemtes           implements          FALSE               5                   \n",
      "inadvertant         inadvertent         TRUE                5                   \n",
      "incase              in case             FALSE               5                   \n",
      "incedious           insidious           TRUE                5                   \n",
      "incompleet          incomplete          TRUE                5                   \n",
      "incomplot           incomplete          TRUE                5                   \n",
      "inconvenant         inconvenient        TRUE                5                   \n",
      "inconvience         inconvenience       TRUE                5                   \n",
      "independant         independent         TRUE                5                   \n",
      "independenent       independent         TRUE                5                   \n",
      "indepnends          independent         TRUE                5                   \n",
      "indepth             in depth            FALSE               5                   \n",
      "indispensible       indispensable       TRUE                5                   \n",
      "inefficite          inefficient         TRUE                5                   \n",
      "inerface            interface           TRUE                5                   \n",
      "infact              in fact             FALSE               5                   \n",
      "influencial         influential         TRUE                5                   \n",
      "inital              initial             TRUE                5                   \n",
      "initinized          initialized         FALSE               5                   \n",
      "initized            initialized         FALSE               5                   \n",
      "innoculate          inoculate           FALSE               5                   \n",
      "insistant           insistent           TRUE                5                   \n",
      "insistenet          insistent           TRUE                5                   \n",
      "instulation         installation        TRUE                5                   \n",
      "intealignt          intelligent         TRUE                5                   \n",
      "intejilent          intelligent         TRUE                5                   \n",
      "intelegent          intelligent         TRUE                5                   \n",
      "intelegnent         intelligent         TRUE                5                   \n",
      "intelejent          intelligent         TRUE                5                   \n",
      "inteligent          intelligent         TRUE                5                   \n",
      "intelignt           intelligent         TRUE                5                   \n",
      "intellagant         intelligent         TRUE                5                   \n",
      "intellegent         intelligent         TRUE                5                   \n",
      "intellegint         intelligent         TRUE                5                   \n",
      "intellgnt           intelligent         TRUE                5                   \n",
      "intensionality      intensionally       FALSE               5                   \n",
      "interate            iterate             FALSE               5                   \n",
      "internation         international       FALSE               5                   \n",
      "interpretate        interpret           FALSE               5                   \n",
      "interpretter        interpreter         TRUE                5                   \n",
      "intertes            interested          FALSE               5                   \n",
      "intertesd           interested          FALSE               5                   \n",
      "invermeantial       environmental       FALSE               5                   \n",
      "irregardless        regardless          TRUE                5                   \n",
      "irresistable        irresistible        TRUE                5                   \n",
      "irritible           irritable           TRUE                5                   \n",
      "islams              muslims             FALSE               5                   \n",
      "isotrop             isotope             FALSE               5                   \n",
      "isreal              israel              FALSE               5                   \n",
      "johhn               john                TRUE                5                   \n",
      "judgement           judgment            TRUE                5                   \n",
      "kippur              kipper              FALSE               5                   \n",
      "knawing             knowing             TRUE                5                   \n",
      "latext              latest              TRUE                5                   \n",
      "leasve              leave               TRUE                5                   \n",
      "lesure              leisure             TRUE                5                   \n",
      "liasion             lesion              TRUE                5                   \n",
      "liason              liaison             TRUE                5                   \n",
      "libary              library             TRUE                5                   \n",
      "likly               likely              TRUE                5                   \n",
      "lilometer           kilometer           TRUE                5                   \n",
      "liquify             liquefy             FALSE               5                   \n",
      "lloyer              layer               FALSE               5                   \n",
      "lossing             losing              TRUE                5                   \n",
      "luser               laser               FALSE               5                   \n",
      "maintanence         maintenance         TRUE                5                   \n",
      "majaerly            majority            FALSE               5                   \n",
      "majoraly            majority            TRUE                5                   \n",
      "maks                masks               FALSE               5                   \n",
      "mandelbrot          Mandelbrot          FALSE               5                   \n",
      "mant                want                FALSE               5                   \n",
      "marshall            marshal             TRUE                5                   \n",
      "maxium              maximum             TRUE                5                   \n",
      "meory               memory              TRUE                5                   \n",
      "metter              better              FALSE               5                   \n",
      "mic                 mike                FALSE               5                   \n",
      "midia               media               TRUE                5                   \n",
      "millenium           millennium          TRUE                5                   \n",
      "miniscule           minuscule           FALSE               5                   \n",
      "minkay              monkey              TRUE                5                   \n",
      "minum               minimum             FALSE               5                   \n",
      "mischievious        mischievous         TRUE                5                   \n",
      "misilous            miscellaneous       FALSE               5                   \n",
      "momento             memento             TRUE                5                   \n",
      "monkay              monkey              TRUE                5                   \n",
      "mosaik              mosaic              TRUE                5                   \n",
      "mostlikely          most likely         FALSE               5                   \n",
      "mousr               mouser              FALSE               5                   \n",
      "mroe                more                FALSE               5                   \n",
      "neccessary          necessary           TRUE                5                   \n",
      "necesary            necessary           TRUE                5                   \n",
      "necesser            necessary           TRUE                5                   \n",
      "neice               niece               FALSE               5                   \n",
      "neighbour           neighbor            TRUE                5                   \n",
      "nemonic             pneumonic           FALSE               5                   \n",
      "nevade              Nevada              TRUE                5                   \n",
      "nickleodeon         nickelodeon         FALSE               5                   \n",
      "nieve               naive               FALSE               5                   \n",
      "noone               no one              FALSE               5                   \n",
      "noticably           noticeably          TRUE                5                   \n",
      "notin               not in              FALSE               5                   \n",
      "nozled              nuzzled             TRUE                5                   \n",
      "objectsion          objects             FALSE               5                   \n",
      "obsfuscate          obfuscate           FALSE               5                   \n",
      "ocassion            occasion            TRUE                5                   \n",
      "occuppied           occupied            TRUE                5                   \n",
      "occurence           occurrence          TRUE                5                   \n",
      "octagenarian        octogenarian        FALSE               5                   \n",
      "olf                 old                 FALSE               5                   \n",
      "opposim             opossum             FALSE               5                   \n",
      "organise            organize            TRUE                5                   \n",
      "organiz             organize            TRUE                5                   \n",
      "orientate           orient              FALSE               5                   \n",
      "oscilascope         oscilloscope        FALSE               5                   \n",
      "oving               moving              FALSE               5                   \n",
      "paramers            parameters          FALSE               5                   \n",
      "parametic           parameter           TRUE                5                   \n",
      "paranets            parameters          FALSE               5                   \n",
      "partrucal           particular          FALSE               5                   \n",
      "pataphysical        metaphysical        TRUE                5                   \n",
      "patten              pattern             TRUE                5                   \n",
      "permissable         permissible         TRUE                5                   \n",
      "permition           permission          TRUE                5                   \n",
      "permmasivie         permissive          TRUE                5                   \n",
      "perogative          prerogative         TRUE                5                   \n",
      "persue              pursue              TRUE                5                   \n",
      "phantasia           fantasia            TRUE                5                   \n",
      "phenominal          phenomenal          TRUE                5                   \n",
      "picaresque          picturesque         TRUE                5                   \n",
      "playwrite           playwright          TRUE                5                   \n",
      "poeses              poesies             FALSE               5                   \n",
      "polation            politician          FALSE               5                   \n",
      "poligamy            polygamy            FALSE               5                   \n",
      "politict            politic             TRUE                5                   \n",
      "pollice             police              TRUE                5                   \n",
      "polypropalene       polypropylene       TRUE                5                   \n",
      "pompom              pompon              FALSE               5                   \n",
      "possable            possible            TRUE                5                   \n",
      "practicle           practical           TRUE                5                   \n",
      "pragmaticism        pragmatism          TRUE                5                   \n",
      "preceeding          preceding           TRUE                5                   \n",
      "precion             precision           TRUE                5                   \n",
      "precios             precision           FALSE               5                   \n",
      "preemptory          peremptory          TRUE                5                   \n",
      "prefices            prefixes            TRUE                5                   \n",
      "prefixt             prefixed            FALSE               5                   \n",
      "presbyterian        Presbyterian        TRUE                5                   \n",
      "presue              pursue              FALSE               5                   \n",
      "presued             pursued             FALSE               5                   \n",
      "privielage          privilege           TRUE                5                   \n",
      "priviledge          privilege           TRUE                5                   \n",
      "proceedures         procedures          TRUE                5                   \n",
      "pronensiation       pronunciation       FALSE               5                   \n",
      "pronisation         pronunciation       FALSE               5                   \n",
      "pronounciation      pronunciation       FALSE               5                   \n",
      "properally          properly            TRUE                5                   \n",
      "proplematic         problematic         TRUE                5                   \n",
      "protray             portray             TRUE                5                   \n",
      "pscolgst            psychologist        FALSE               5                   \n",
      "psicolagest         psychologist        TRUE                5                   \n",
      "psycolagest         psychologist        TRUE                5                   \n",
      "quoz                quiz                TRUE                5                   \n",
      "radious             radius              TRUE                5                   \n",
      "ramplily            rampantly           FALSE               5                   \n",
      "reccomend           recommend           TRUE                5                   \n",
      "reccona             raccoon             FALSE               5                   \n",
      "recieve             receive             FALSE               5                   \n",
      "reconise            recognize           TRUE                5                   \n",
      "rectangeles         rectangle           TRUE                5                   \n",
      "redign              redesign            FALSE               5                   \n",
      "reoccurring         recurring           TRUE                5                   \n",
      "repitition          repetition          TRUE                5                   \n",
      "replasments         replacement         TRUE                5                   \n",
      "reposable           responsible         FALSE               5                   \n",
      "reseblence          resemblance         TRUE                5                   \n",
      "respct              respect             TRUE                5                   \n",
      "respecally          respectfully        TRUE                5                   \n",
      "roon                room                FALSE               5                   \n",
      "rought              roughly             FALSE               5                   \n",
      "rsx                 RSX                 FALSE               5                   \n",
      "rudemtry            rudimentary         FALSE               5                   \n",
      "runnung             running             TRUE                5                   \n",
      "sacreligious        sacrilegious        FALSE               5                   \n",
      "saftly              safely              TRUE                5                   \n",
      "salut               salute              TRUE                5                   \n",
      "satifly             satisfy             TRUE                5                   \n",
      "scrabdle            scrabble            FALSE               5                   \n",
      "searcheable         searchable          FALSE               5                   \n",
      "secion              section             TRUE                5                   \n",
      "seferal             several             TRUE                5                   \n",
      "segements           segments            TRUE                5                   \n",
      "sence               sense               TRUE                5                   \n",
      "seperate            separate            TRUE                5                   \n",
      "sherbert            sherbet             FALSE               5                   \n",
      "sicolagest          psychologist        FALSE               5                   \n",
      "sieze               seize               FALSE               5                   \n",
      "simpfilty           simplicity          TRUE                5                   \n",
      "simplye             simply              TRUE                5                   \n",
      "singal              signal              TRUE                5                   \n",
      "sitte               site                TRUE                5                   \n",
      "situration          situation           TRUE                5                   \n",
      "slyph               sylph               FALSE               5                   \n",
      "smil                smile               TRUE                5                   \n",
      "snuck               sneaked             FALSE               5                   \n",
      "sometmes            sometimes           TRUE                5                   \n",
      "soonec              sonic               FALSE               5                   \n",
      "specificialy        specifically        TRUE                5                   \n",
      "spel                spell               TRUE                5                   \n",
      "spoak               spoke               FALSE               5                   \n",
      "sponsered           sponsored           TRUE                5                   \n",
      "stering             steering            TRUE                5                   \n",
      "straightjacket      straitjacket        FALSE               5                   \n",
      "stumach             stomach             TRUE                5                   \n",
      "stutent             student             TRUE                5                   \n",
      "styleguide          style guide         FALSE               5                   \n",
      "subisitions         substitutions       FALSE               5                   \n",
      "subjecribed         subscribed          TRUE                5                   \n",
      "subpena             subpoena            TRUE                5                   \n",
      "substations         substitutions       FALSE               5                   \n",
      "suger               sugar               TRUE                5                   \n",
      "supercede           supersede           FALSE               5                   \n",
      "superfulous         superfluous         TRUE                5                   \n",
      "susan               Susan               TRUE                5                   \n",
      "swimwear            swim wear           FALSE               5                   \n",
      "syncorization       synchronization     FALSE               5                   \n",
      "taff                tough               FALSE               5                   \n",
      "taht                that                FALSE               5                   \n",
      "tattos              tattoos             FALSE               5                   \n",
      "techniquely         technically         TRUE                5                   \n",
      "teh                 the                 FALSE               5                   \n",
      "tem                 team                TRUE                5                   \n",
      "teo                 two                 TRUE                5                   \n",
      "teridical           theoretical         FALSE               5                   \n",
      "tesst               test                TRUE                5                   \n",
      "tets                tests               FALSE               5                   \n",
      "thanot              than or             FALSE               5                   \n",
      "theirselves         themselves          TRUE                5                   \n",
      "theridically        theoretical         FALSE               5                   \n",
      "thredically         theoretically       TRUE                5                   \n",
      "thruout             throughout          FALSE               5                   \n",
      "ths                 this                TRUE                5                   \n",
      "titalate            titillate           FALSE               5                   \n",
      "tobagan             tobaggon            FALSE               5                   \n",
      "tommorrow           tomorrow            TRUE                5                   \n",
      "tomorow             tomorrow            TRUE                5                   \n",
      "tradegy             tragedy             TRUE                5                   \n",
      "trubbel             trouble             FALSE               5                   \n",
      "ttest               test                TRUE                5                   \n",
      "tunnellike          tunnel like         FALSE               5                   \n",
      "tured               turned              TRUE                5                   \n",
      "tyrrany             tyranny             TRUE                5                   \n",
      "unatourral          unnatural           TRUE                5                   \n",
      "unaturral           unnatural           TRUE                5                   \n",
      "unconisitional      unconstitutional    TRUE                5                   \n",
      "unconscience        unconscious         TRUE                5                   \n",
      "underladder         under ladder        FALSE               5                   \n",
      "unentelegible       unintelligible      TRUE                5                   \n",
      "unfortunently       unfortunately       TRUE                5                   \n",
      "unnaturral          unnatural           TRUE                5                   \n",
      "upcast              up cast             FALSE               5                   \n",
      "upmost              utmost              TRUE                5                   \n",
      "uranisium           uranium             TRUE                5                   \n",
      "verison             version             FALSE               5                   \n",
      "vinagarette         vinaigrette         FALSE               5                   \n",
      "volumptuous         voluptuous          TRUE                5                   \n",
      "volunteerism        voluntarism         FALSE               5                   \n",
      "volye               volley              FALSE               5                   \n",
      "wadting             wasting             TRUE                5                   \n",
      "waite               wait                TRUE                5                   \n",
      "wan't               won't               TRUE                5                   \n",
      "warloord            warlord             FALSE               5                   \n",
      "whaaat              what                TRUE                5                   \n",
      "whard               ward                TRUE                5                   \n",
      "whimp               wimp                FALSE               5                   \n",
      "wicken              weaken              FALSE               5                   \n",
      "wierd               weird               FALSE               5                   \n",
      "wrank               rank                FALSE               5                   \n",
      "writeen             righten             FALSE               5                   \n",
      "writting            writing             TRUE                5                   \n",
      "wundeews            windows             FALSE               5                   \n",
      "yeild               yield               TRUE                5                   \n",
      "youe                your                TRUE                5                   \n",
      "Evaluation:\n",
      "Recall:    0.6197440585009141\n",
      "Precision: 0.12449504223283143\n",
      "F1 score:  0.2073394495412844\n",
      "CPU times: user 54min 16s, sys: 7.83 s, total: 54min 24s\n",
      "Wall time: 54min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "\n",
    "sumTrueCorrections = 0\n",
    "sumFalseCorrections = 0\n",
    "sumProposedCorrections = 0\n",
    "\n",
    "with open('batch0.tab') as tsvfile :\n",
    "  reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "  print(\"{1:20}{2:20}{0:20}{3:20}\".format(\"Gold in candidates\",\"Test word\",\"Gold correction\",\"Size of candidate list\"))\n",
    "  print(\"-\"*82)\n",
    "  for row in reader :\n",
    "        proposedCorrections = TEST_propose_word_corrections(row[0])\n",
    "        sumProposedCorrections += len(proposedCorrections)\n",
    "        if row[1] in proposedCorrections :\n",
    "            sumTrueCorrections += 1\n",
    "            print(\"{1:20}{2:20}{0:20}{3:20}\".format(\"TRUE\",row[0],row[1],str(len(proposedCorrections))))\n",
    "        else :\n",
    "            sumFalseCorrections += 1\n",
    "            print(\"{1:20}{2:20}{0:20}{3:20}\".format(\"FALSE\",row[0],row[1],str(len(proposedCorrections))))\n",
    "\n",
    "recallCorrections = sumTrueCorrections / (sumTrueCorrections + sumFalseCorrections)\n",
    "precisionCorrections = sumTrueCorrections / sumProposedCorrections\n",
    "\n",
    "print(\"Evaluation:\")\n",
    "print(\"Recall:    \" + str(recallCorrections))\n",
    "print(\"Precision: \" + str(precisionCorrections))\n",
    "print(\"F1 score:  \" + str(2 * precisionCorrections * recallCorrections / (precisionCorrections + recallCorrections)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtJOw1RUh3gg"
   },
   "source": [
    "Man kann die Ergebnisse dann mit denen von Aspell vergleichen: http://aspell.net/test/cur/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avZEDXl0h3gg"
   },
   "source": [
    "# Literatur\n",
    "\n",
    "Daniel Jurafsky & James H. Martin. 2021. Speech and Language Processing. Draft of September 21, 2021. https://web.stanford.edu/~jurafsky/slp3/."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
